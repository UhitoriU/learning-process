{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载向量数据库\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5009/576814584.py:1: LangChainDeprecationWarning: As of langchain-core 0.3.0, LangChain uses pydantic v2 internally. The langchain.pydantic_v1 module was a compatibility shim for pydantic v1, and should no longer be used. Please update the code to import from Pydantic directly.\n",
      "\n",
      "For example, replace imports like: `from langchain.pydantic_v1 import BaseModel`\n",
      "with: `from pydantic import BaseModel`\n",
      "or the v1 compatibility namespace if you are working in a code base that has not been fully upgraded to pydantic 2 yet. \tfrom pydantic.v1 import BaseModel\n",
      "\n",
      "  from zhipuai_embedding import ZhipuAIEmbeddings\n"
     ]
    }
   ],
   "source": [
    "from zhipuai_embedding import ZhipuAIEmbeddings\n",
    "\n",
    "from langchain.vectorstores.chroma import Chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "zhipuai_api_key = os.environ['ZHIPUAI_API_KEY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义Embeddings\n",
    "embedding = ZhipuAIEmbeddings()\n",
    "\n",
    "# 向量数据库持久化路径\n",
    "persist_directory = '../data_base/vector_db/chroma'\n",
    "\n",
    "# 加载向量数据库\n",
    "vectordb = Chroma(\n",
    "    persist_directory=persist_directory,\n",
    "    embedding_function=embedding\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "向量库中存储的数量：20\n"
     ]
    }
   ],
   "source": [
    "print(f\"向量库中存储的数量：{vectordb._collection.count()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "检索到的内容数：3\n"
     ]
    }
   ],
   "source": [
    "# 测试一下加载的向量数据库，使用一个问题 query 进行向量检索\n",
    "question = \"什么是prompt engineering？\"\n",
    "docs = vectordb.similarity_search(question,k=3)\n",
    "print(f\"检索到的内容数：{len(docs)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "检索到的第0个内容：\n",
      "3\n",
      "1.4.1\n",
      "式(1.1) 和式(1.2) 的解释. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n",
      "4\n",
      "第2 章模型评估与选择\n",
      "5\n",
      "2.1\n",
      "经验误差与过拟合\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n",
      "5\n",
      "2.2\n",
      "评估方法\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n",
      "5\n",
      "2.2.1\n",
      "算法参数（超参数）与模型参数. . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n",
      "6\n",
      "2.2.2\n",
      "验证集. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n",
      "6\n",
      "2.3\n",
      "性能度量\n",
      "-----------------------------------------------------\n",
      "检索到的第1个内容：\n",
      "39\n",
      "4.5.1\n",
      "图(4.10) 的解释\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n",
      "39\n",
      "4.5.2\n",
      "图(4.11) 的解释\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n",
      "39\n",
      "第5 章神经网络\n",
      "41\n",
      "5.1\n",
      "神经元模型. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n",
      "41\n",
      "5.2\n",
      "感知机与多层网络\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n",
      "41\n",
      "5.2.1\n",
      "式(5.1) 和式(5.2) 的推导. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n",
      "41\n",
      "5.2.2\n",
      "-----------------------------------------------------\n",
      "检索到的第2个内容：\n",
      "23\n",
      "→_→\n",
      "配套视频教程：https://www.bilibili.com/video/BV1Mh411e7VU\n",
      "←_←\n",
      "-----------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for i,doc in enumerate(docs):\n",
    "    print(f\"检索到的第{i}个内容：\\n{doc.page_content}\",end=\"\\n-----------------------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建一个LLM\n",
    "import os\n",
    "OPENAI_API_KEY = os.environ[\"OPENAI_API_KEY\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='您好，我是一名智能助手，专门为您提供各种服务和信息。我具有丰富的知识和经验，可以帮助您解决问题和获取所需的信息。如果您有任何需求或疑问，都可以随时向我咨询，我会竭尽所能为您提供帮助。希望我们可以愉快地合作！如果有任何问题，请随时向我提问。', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 129, 'prompt_tokens': 20, 'total_tokens': 149, 'completion_tokens_details': {'audio_tokens': None, 'reasoning_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-bd2a0802-2272-49f7-b7e7-008c919268a5-0', usage_metadata={'input_tokens': 20, 'output_tokens': 129, 'total_tokens': 149, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 0}})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\",temperature=0,openai_api_key=os.environ[\"OPENAI_API_KEY\"],openai_api_base=os.environ[\"BASE_URL\"])\n",
    "\n",
    "llm.invoke(\"请你自我介绍一下自己！\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构建检索问答链\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "template = \"\"\"使用以下上下文来回答最后的问题。如果你不知道答案，就说你不知道，不要试图编造答\n",
    "案。最多使用三句话。尽量使答案简明扼要。总是在回答的最后说“谢谢你的提问！”。\n",
    "{context}\n",
    "问题: {question}\n",
    "\"\"\"\n",
    "\n",
    "QA_CHAIN_PROMPT = PromptTemplate(input_variables=[\"context\",\"question\"],template=template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建一个基于模板的检索链\n",
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm,\n",
    "    retriever=vectordb.as_retriever(),\n",
    "    return_source_documents=True,\n",
    "    chain_type_kwargs={\"prompt\":QA_CHAIN_PROMPT}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 检索问答链效果测试\n",
    "question_1 = \"什么是南瓜书？\"\n",
    "question_2 = \"王阳明是谁？\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5009/752743503.py:2: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  result = qa_chain({\"query\":question_1})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "大模型+知识库后回答 question_1 的结果：\n",
      "南瓜书是一本机器学习领域的书籍，致力于解析西瓜书中比较难理解的公式，以及补充部分公式的推导细节。谢谢你的提问！\n"
     ]
    }
   ],
   "source": [
    "# 基于召回结果和query结合起来构建的prompt效果\n",
    "result = qa_chain({\"query\":question_1})\n",
    "print(\"大模型+知识库后回答 question_1 的结果：\")\n",
    "print(result[\"result\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "大模型+知识库后回答 question_2 的结果：\n",
      "王阳明是明代思想家、教育家，提出“心即理”、“知行合一”等哲学观念，被认为是中国哲学史上的重要人物。谢谢你的提问！\n"
     ]
    }
   ],
   "source": [
    "result = qa_chain({\"query\": question_2})\n",
    "print(\"大模型+知识库后回答 question_2 的结果：\")\n",
    "print(result[\"result\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5009/1089164201.py:6: LangChainDeprecationWarning: The method `BaseChatModel.predict` was deprecated in langchain-core 0.1.7 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  llm.predict(prompt_template)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'南瓜书是由德国心理学家佛洛伊德（Sigmund Freud）所著的著作，讲述了一个南瓜成为了心理学家。这本书以幽默的方式探讨了心理学的概念和理论，引发了人们对心理学的思考，并成为心理学教育领域中的经典之作。'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 大模型自己回答的效果\n",
    "prompt_template = \"\"\"请回答下列问题:\n",
    "                            {}\"\"\".format(question_1)\n",
    "\n",
    "# 基于大模型的问答\n",
    "llm.predict(prompt_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'王阳明（1472年 - 1529年），明代著名学者、政治家、军事家。他为心学创立者，提出“知行合一”、“格物致知”等重要观念，对后世影响深远。在政治上主张“致良知”、“治民以仁”，强调内在修养和道德修养的重要性。'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_template = \"\"\"请回答下列问题:\n",
    "                            {}\"\"\".format(question_2)\n",
    "\n",
    "# 基于大模型的问答\n",
    "llm.predict(prompt_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5009/592791389.py:6: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  memory = ConversationBufferMemory(\n"
     ]
    }
   ],
   "source": [
    "# 添加历史对话的记忆功能\n",
    "# 记忆(Memory)\n",
    "\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "memory = ConversationBufferMemory(\n",
    "    memory_key=\"chat_history\",\n",
    "    return_messages=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "抱歉，我无法回答这个问题。因为提供的文本片段未提供关于具体课程内容和教授这方面知识的信息。您可能需要查阅更多相关内容或直接询问相关领域的专家以获取答案。\n"
     ]
    }
   ],
   "source": [
    "# 对话检索链(ConversationalRetrievvalChain)\n",
    "\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "\n",
    "retriever = vectordb.as_retriever()\n",
    "\n",
    "qa = ConversationalRetrievalChain.from_llm(\n",
    "    llm,\n",
    "    retriever=retriever,\n",
    "    memory=memory\n",
    ")\n",
    "question = \"我可以学习到关于提示工程的知识吗？\"\n",
    "result = qa({\"question\":question})\n",
    "print(result['answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "很抱歉，我不知道。\n"
     ]
    }
   ],
   "source": [
    "question = \"为什么这门课需要教这方面的知识？\"\n",
    "result = qa({\"question\": question})\n",
    "print(result['answer'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-universe",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
